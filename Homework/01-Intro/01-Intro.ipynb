{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_Jan = pd.read_parquet(path=\"Data/yellow_tripdata_2023-01.parquet\")\n",
    "df_Feb = pd.read_parquet(path=\"Data/yellow_tripdata_2023-02.parquet\")\n",
    "pd.options.mode.chained_assignment = None \n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 19 columns in this dataset.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {df_Jan.shape[1]} columns in this dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duration(row : pd.Series) -> float:\n",
    "    \"\"\"Returns the duration between dropoff and pickup times\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): Slice of dataframe containing \"tpep_pickup_datetime\" and \"tpep_dropoff_datetime\"\n",
    "\n",
    "    Returns:\n",
    "        float: The duration of the trip\n",
    "    \"\"\"\n",
    "    \n",
    "    duration = row[\"tpep_dropoff_datetime\"] - row[\"tpep_pickup_datetime\"]\n",
    "    minutes = duration.total_seconds() / 60.0\n",
    "    return minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standard deviation of the trips in January is 42.59435124195483.\n"
     ]
    }
   ],
   "source": [
    "df_Jan[\"duration\"] = df_Jan.apply(get_duration, axis = 1)\n",
    "cov = np.cov(df_Jan.duration, bias = False) # We use (N - 1) because we want to calculate sample covariance\n",
    "print(f\"The standard deviation of the trips in January is {np.sqrt(cov)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.1220282212598% of the data is left\n"
     ]
    }
   ],
   "source": [
    "rows = (df_Jan.duration >= 1) & (df_Jan.duration <= 60)\n",
    "print(f\"{rows.sum() / df_Jan.shape[0] * 100}% of the data is left\")\n",
    "df_Jan_subset = df_Jan.loc[rows, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new matrix has 515 columns.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "df_Jan_subset['DOID'] = df_Jan_subset['DOLocationID'].astype(str)\n",
    "df_Jan_subset['PUID'] = df_Jan_subset['PULocationID'].astype(str)\n",
    "X_dict = df_Jan_subset[['DOID', 'PUID']].to_dict('records')\n",
    "transformer = DictVectorizer()\n",
    "X_train = transformer.fit_transform(X_dict)\n",
    "print(f\"The new matrix has {X_train.shape[1]} columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE of our model is: 7.649261822035489.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "model = LinearRegression()\n",
    "model.fit(X = X_train, y = df_Jan_subset['duration'])\n",
    "predictions = model.predict(X_train)\n",
    "rmse = np.sqrt(mse(df_Jan_subset['duration'], predictions))\n",
    "print(f\"The RMSE of our model is: {rmse}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test-RMSE is: 7.811821332387183.\n"
     ]
    }
   ],
   "source": [
    "df_Feb['DOID'] = df_Feb['DOLocationID'].astype(str)\n",
    "df_Feb['PUID'] = df_Feb['PULocationID'].astype(str)\n",
    "\n",
    "df_Feb['duration'] = df_Feb.apply(get_duration, axis = 1)\n",
    "rows_test = (df_Feb.duration >= 1) & (df_Feb.duration <= 60)\n",
    "df_Feb_subset = df_Feb.loc[rows_test, :]\n",
    "\n",
    "X_test = transformer.transform(df_Feb_subset[['DOID', 'PUID']].to_dict('records'))\n",
    "y_test = df_Feb_subset['duration']\n",
    "\n",
    "test_predictions = model.predict(X_test)\n",
    "test_rmse = np.sqrt(mse(y_test, test_predictions))\n",
    "print(f\"The test-RMSE is: {test_rmse}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
